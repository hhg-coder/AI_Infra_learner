#include <iostream>
#include <thread>
#include <mutex>
#include <condition_variable>
#include <queue>
#include <vector>
#include <cstring>
#include <atomic>

// 1. 信号量实现 (基于C++11的mutex和condition_variable)
class Semaphore {
public:
    Semaphore(int count = 0) : count_(count) {}

    void signal() {
        std::unique_lock<std::mutex> lock(mutex_);
        ++count_;
        cv_.notify_one();
    }

    void wait() {
        std::unique_lock<std::mutex> lock(mutex_);
        cv_.wait(lock, [this]() { return count_ > 0; });
        --count_;
    }

private:
    std::mutex mutex_;
    std::condition_variable cv_;
    int count_;
};

// 2. 模拟网络数据结构
struct NetworkData {
    char buffer[1024]; // 假设的数据包大小
    size_t size;       // 实际数据长度
};

// 3. 固定大小的内存池
template<typename T, size_t PoolSize = 300>
class MemoryPool {
public:
    MemoryPool() {
        // 预先分配所有对象
        for (size_t i = 0; i < PoolSize; ++i) {
            free_list.push(&pool[i]);
        }
    }

    T* allocate() {
        std::lock_guard<std::mutex> lock(mutex_);
        if (free_list.empty()) {
            return nullptr; // 池已耗尽，可根据需要扩展
        }
        T* obj = free_list.front();
        free_list.pop();
        return obj;
    }

    void deallocate(T* obj) {
        std::lock_guard<std::mutex> lock(mutex_);
        free_list.push(obj);
    }

    size_t available() const {
        return free_list.size();
    }

private:
    T pool[PoolSize];         // 预先分配的内存块
    std::queue<T*> free_list; // 空闲对象队列
    mutable std::mutex mutex_; // 保护空闲队列的互斥锁
};

// 4. 全局资源
MemoryPool<NetworkData> data_pool; // 内存池，预分配300个NetworkData
Semaphore data_available(0);       // 信号量：表示可处理的数据包数量
std::queue<NetworkData*> data_queue; // 共享数据队列
std::mutex queue_mutex;           // 保护数据队列的互斥锁
std::atomic<bool> running{true};   // 控制线程运行标志

// 5. 网络数据接收线程（模拟生产者）
void network_receiver_thread() {
    while (running) {
        // 模拟从网络接收数据...
        NetworkData* data = data_pool.allocate();
        if (data == nullptr) {
            std::cerr << "内存池耗尽！等待..." << std::endl;
            std::this_thread::sleep_for(std::chrono::milliseconds(10));
            continue;
        }

        // 填充模拟数据
        std::strcpy(data->buffer, "模拟网络数据");
        data->size = strlen(data->buffer);

        // 将数据加入队列并通知处理线程
        {
            std::lock_guard<std::mutex> lock(queue_mutex);
            data_queue.push(data);
        }
        data_available.signal(); // 增加可用数据信号量

        std::this_thread::sleep_for(std::chrono::milliseconds(1)); // 模拟接收间隔
    }
}

// 6. 数据处理线程（消费者）
const int CONSUMER_COUNT = 4; // 消费者线程数量

void data_processor_thread(int id) {
    while (running) {
        data_available.wait();

        NetworkData* data = nullptr;
        {
            std::lock_guard<std::mutex> lock(queue_mutex);
            if (!data_queue.empty()) {
                data = data_queue.front();
                data_queue.pop();
            }
        }

        if (data) {
            std::cout << "[消费者" << id << "] 处理数据: " << data->buffer << " (大小: " << data->size << ")" << std::endl;
            data_pool.deallocate(data);
        }
    }
}

int main() {
    // 启动网络接收线程和数据处理线程
    std::thread receiver(network_receiver_thread);
    std::vector<std::thread> consumers;
    for (int i = 0; i < CONSUMER_COUNT; ++i) {
        consumers.emplace_back(data_processor_thread, i + 1);
    }

    // 让程序运行一段时间
    std::this_thread::sleep_for(std::chrono::seconds(3));

    // 停止线程
    running = false;
    for (int i = 0; i < CONSUMER_COUNT; ++i) {
        data_available.signal();
    }
    receiver.join();
    for (auto& t : consumers) t.join();

    std::cout << "程序结束。内存池剩余可用对象: " << data_pool.available() << std::endl;

    return 0;
}

把项目中使用到的内存池技术讲清楚：
内存池技术，主要是用来高效管理大量同类型对象的内存分配和释放，避免频繁的 new/delete 或 malloc/free，提升性能和资源利用率。
代码里的内存池原理
预分配固定数量的对象
在 MemoryPool 构造函数里，预先分配了 300 个 NetworkData 对象（T pool[PoolSize]），并把它们的指针都放进 free_list 队列。
分配对象（allocate）
当需要一个新对象时，从 free_list 队列里弹出一个指针，直接返回。这样不用每次都 new 或 malloc，速度快，碎片少。
释放对象（deallocate）
用完对象后，把指针重新放回 free_list 队列，下次可以再用。这样对象会被循环利用，避免内存泄漏和频繁分配释放。
线程安全
分配和释放都用 std::mutex 加锁，保证多线程环境下不会出错。
池耗尽处理
如果池里的对象都被分配出去了（free_list.empty()），allocate() 返回 nullptr，生产者线程会等待一会儿再尝试分配。
优点
高性能：避免频繁的系统级内存分配和释放，速度快。
低碎片：所有对象都在一块连续内存里，减少内存碎片。
易管理：对象生命周期由池统一管理，避免内存泄漏。
线程安全：适合多线程场景。


为什么要预分配预分配固定数量的对象？
预分配固定数量的对象有以下几个主要原因：
提升性能
预分配后，分配和释放对象只需操作指针队列，无需频繁调用系统的 new/delete 或 malloc/free，速度更快。
减少内存碎片
所有对象都在一块连续内存区域，避免了频繁分配释放导致的内存碎片问题。
易于管理和回收
对象统一由内存池管理，生命周期清晰，能有效防止内存泄漏。
线程安全
通过加锁保护分配和释放，适合多线程环境。
适合对象数量可预估的场景
如果你能预估最大并发需求，预分配可以保证系统稳定运行，不会因内存不足而频繁失败。
总结：
预分配固定数量对象是为了高效、稳定、可控地管理内存，特别适合高并发、对象数量可预估的场景。


这里信号量的作用是什么？
信号量 data_available 的作用是实现生产者和消费者线程之间的同步，保证：
只有当有数据可处理时，消费者线程才会被唤醒去处理数据；
生产者每生产一个数据包，就调用 signal() 增加信号量，通知消费者有新数据；
消费者线程在 wait() 处阻塞，直到信号量大于 0，才会继续处理队列中的数据。
这样可以防止消费者线程“空转”，确保每次处理的都是实际收到的数据，实现高效的线程协作。


这段代码中，虽然提前预分配了T pool[PoolSize];但是在deallocate的过程中，NetworkData不是新建的吗？
在你的代码里，NetworkData 对象不是新建的，而是从预分配的 pool 数组里“借用”的。
具体流程如下：
预分配阶段
构造 MemoryPool 时，T pool[PoolSize];（这里是 NetworkData pool[300];）会一次性分配 300 个对象在栈或堆上（取决于类的声明位置），并把每个对象的指针都放进 free_list 队列。
allocate() 分配对象
当你需要一个对象时，从 free_list 队列里弹出一个指针，返回给调用者。这个指针指向的是 pool 数组里的某个 NetworkData，不是新建的。
deallocate() 归还对象
用完对象后，把指针重新放回 free_list 队列。这样下次再用时，还是用同一个对象。
结论：
整个生命周期里，NetworkData 对象只在程序启动时分配一次，之后都是“借用”和“归还”，没有动态 new，也没有重复构造或析构。
你看到的 deallocate 只是把指针放回队列，并没有新建对象。
