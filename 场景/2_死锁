代码示例：
#include <iostream>
#include <thread>
#include <mutex>

std::mutex mutexA;
std::mutex mutexB;

void thread1() {
    std::lock_guard<std::mutex> lockA(mutexA);
    std::this_thread::sleep_for(std::chrono::milliseconds(100));
    std::lock_guard<std::mutex> lockB(mutexB);
    std::cout << "Thread 1 acquired both locks\n";
}

void thread2() {
    std::lock_guard<std::mutex> lockB(mutexB);
    std::this_thread::sleep_for(std::chrono::milliseconds(100));
    std::lock_guard<std::mutex> lockA(mutexA);
    std::cout << "Thread 2 acquired both locks\n";
}

int main() {
    std::thread t1(thread1);
    std::thread t2(thread2);
    t1.join();
    t2.join();
    return 0;
}

解释：

thread1 先锁 mutexA，再锁 mutexB。
thread2 先锁 mutexB，再锁 mutexA。
如果 thread1 获得了 mutexA，thread2 获得了 mutexB，两个线程都在等待对方释放锁，造成死锁。


预防死锁的常用方法
统一加锁顺序
所有线程按照相同顺序加锁，避免循环等待。

代码示例：
#include <iostream>
#include <thread>
#include <mutex>

std::mutex mutexA;
std::mutex mutexB;

void thread1() {
    std::lock(mutexA, mutexB);
    std::lock_guard<std::mutex> lockA(mutexA, std::adopt_lock);
    std::lock_guard<std::mutex> lockB(mutexB, std::adopt_lock);
    std::cout << "Thread 1 acquired both locks\n";
}

void thread2() {
    std::lock(mutexA, mutexB);
    std::lock_guard<std::mutex> lockA(mutexA, std::adopt_lock);
    std::lock_guard<std::mutex> lockB(mutexB, std::adopt_lock);
    std::cout << "Thread 2 acquired both locks\n";
}

int main() {
    std::thread t1(thread1);
    std::thread t2(thread2);
    t1.join();
    t2.join();
    return 0;
}

std::adopt_lock 是 C++11 标准库中的一个标签（tag），用于告诉 std::lock_guard 或 std::unique_lock，互斥锁已经被当前线程手动加锁了，不需要再自动加锁。
推荐多锁时用 std::lock + std::adopt_lock，否则不要用



场景描述：

在某导航雷达软件开发项目中，系统需要同时处理雷达数据采集和目标跟踪显示。开发团队采用多线程设计：

线程A负责从雷达硬件读取原始数据，并将数据写入共享缓冲区（Buffer）。
线程B负责从共享缓冲区读取数据，进行目标跟踪和界面显示。
为保证数据一致性，两个线程都需要对共享缓冲区加锁（mutex）。此外，线程B在处理数据时还需要访问一个全局配置对象（Config），该对象也有自己的锁。

某次代码重构后，出现了死锁：

线程A先锁住Buffer，再尝试锁Config。
线程B先锁住Config，再尝试锁Buffer。
当两个线程分别持有一个锁并等待对方释放另一个锁时，系统陷入死锁，雷达界面卡死。
解决方法：

统一加锁顺序
规定所有线程在访问Buffer和Config时，必须先锁Buffer，再锁Config，禁止反向加锁。这样可以避免循环等待，消除死锁。

使用更细粒度的锁
如果可能，将Buffer和Config的锁进一步细分，减少锁的持有时间和范围，降低死锁概率。

尝试锁（trylock）和超时机制
使用trylock代替阻塞锁，如果获取不到锁则释放已持有的锁并重试，避免永久等待。

锁合并
如果Buffer和Config经常一起被访问，可以考虑合并为一个大锁，简化同步逻辑。


提升加了锁的程序性能的方法有：

减小锁的粒度
将大范围的锁拆分为更细粒度的锁，只锁必要的数据结构，减少锁竞争。

缩短临界区
只在必须保护的数据操作前后加锁，避免在锁内执行耗时操作（如IO、复杂计算）。

使用读写锁
对于读多写少的场景，使用读写锁（如pthread_rwlock_t），允许多个线程同时读，只有写时才独占。

减少锁的数量
合并频繁一起访问的数据的锁，减少锁的数量，降低死锁和竞争概率。

无锁/原子操作
对简单数据（如计数器）可用原子操作（如stdatomic.h），避免加锁。

避免嵌套锁和锁的递归
简化锁的层级，减少锁等待时间。

锁分离与分区
对于大数据结构（如哈希表），可分区加锁，每个分区独立锁，提高并发度。

减少线程数量
线程过多会导致频繁上下文切换，合理控制线程数量。

使用条件变量或信号量
让线程在等待资源时挂起，避免忙等浪费CPU。

分析和优化热点
使用性能分析工具（如perf、VTune）定位锁竞争热点，有针对性优化。

总结：
核心思想是减少锁的竞争和持有时间，提升并发度和资源利用率。




