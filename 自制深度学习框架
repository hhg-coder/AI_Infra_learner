
data 张量类Tensor的实现和Tensor初始化方法
layer 算子的实现
parser Pnnx表达式的解析类
runtime 计算图结构，解析和运行时相关

推理过程：
模型加载->构建推理计算图（计算节点）->图像预处理->前向推理->后处理(softmax)->结果

1、自研推理框架的原因主要有以下几点：
学习和研究目的
通过自研，可以深入理解深度学习推理的底层原理，包括算子实现、内存管理、计算图调度等，有助于提升底层开发能力
轻量化和可控性
自研框架可以做到极致精简，只保留所需功能，便于嵌入式、边缘端等资源受限场景部署，同时代码完全可控，便于调试和优化。
和onnx的区别：
onnx为了适配各种模型，把算子拆分的很小，就是add,mul之类的，这样对推理性能会有影响，而自制推理框架则可以将算子保留甚至融合算子，提高推理速度。


1. 张量（Tensor）的数据结构设计，如何支持高效的计算和内存管理？
框架中的张量（如 Tensor<float>）通常采用三维（channels, rows, cols）结构，底层用一维连续内存（如 std::vector 或裸指针）存储数据，保证数据访问的局部性和高效性。
支持切片（slice）、矩阵指针（matrix_raw_ptr）等接口，方便算子高效访问和操作数据。
内存分配和释放由智能指针（如 std::shared_ptr）管理，避免内存泄漏。
通过批量操作和矩阵库（如 Armadillo）加速计算


2. 推理过程中，如何实现前向传播？是否有支持动态图/静态图？
框架采用静态计算图（static graph）方式，模型加载时先解析网络结构，构建好算子节点和依赖关系。
前向传播时，依次遍历计算图节点，调用每个算子的 Forward 方法，输入输出张量在节点间传递。
目前主要支持静态图（即图结构在推理前固定），不支持动态图（如 PyTorch 的 eager 模式）。

3. 你们的算子实现是如何做的？比如卷积、激活、池化等。
卷积：采用 Im2Col + GEMM（矩阵乘法）方式实现，支持分组卷积和 bias，详见 convolution.cpp。
激活：如 ReLU、SiLU、Softmax 等，直接对张量元素逐一操作或按通道处理。
池化：如最大池化、自适应平均池化，遍历窗口区域，取最大/平均值输出。
每个算子都实现了标准的 Forward 接口，便于统一调度和扩展。

4. Softmax 层的实现细节，是否有数值稳定性处理？
Softmax 层会先对每个通道（或 batch）减去最大值（max trick），防止指数溢出，实现数值稳定性。
计算流程：
找到最大值
所有元素减去最大值后取 exp
求和归一化
这样可以避免大数溢出，提高数值精度。

5. 如何处理 batch 推理？支持多线程或并发吗？
框架支持 batch 推理：输入为张量数组（vector<sftensor>），每个 batch 独立处理，输出同样为数组。
目前推理流程是串行处理每个 batch，没有内置多线程并发，但可以在外部用多线程并行调用推理接口，或后续扩展算子内部并行。
由于每个 batch 独立，理论上很容易扩展为多线程并发推理。
